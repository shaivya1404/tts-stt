{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# TTS/STT Services - Complete Deployment & Testing Notebook\n\nThis notebook deploys and tests the TTS and STT ML services on Google Colab with GPU acceleration.\n\n## What This Notebook Does\n1. **Deploy Services** - Install dependencies and start STT/TTS services\n2. **Setup ngrok** - Create public URLs for the services\n3. **Health checks** - Verify both services are running\n4. **STT testing** - Speech-to-Text transcription\n5. **TTS testing** - Text-to-Speech synthesis\n6. **Multi-language testing**\n7. **Performance measurement**\n\n## Prerequisites\n- Google Colab with GPU runtime (Runtime ‚Üí Change runtime type ‚Üí T4 GPU)\n- ngrok account and auth token (free at https://ngrok.com)",
   "metadata": {
    "id": "header"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Step 1: Install Dependencies & Setup",
   "metadata": {
    "id": "setup-header"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": "# @title 1.1 Install All Dependencies\n# Install core dependencies\n!pip install -q requests pyngrok fastapi uvicorn python-multipart pydantic pydantic-settings loguru nest_asyncio\n\n# Install ML dependencies\n!pip install -q faster-whisper TTS numpy\n\n# Check GPU availability\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"‚ö†Ô∏è No GPU detected! Performance will be slow.\")\n    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí Select T4 GPU\")\n\nprint(\"\\n‚úÖ Dependencies installed!\")"
  },
  {
   "cell_type": "code",
   "source": "# @title 1.2 Setup ngrok Authentication\n# @markdown Get your auth token from https://dashboard.ngrok.com/get-started/your-authtoken\n\n# Install pyngrok if needed\nimport subprocess\nimport sys\ntry:\n    from pyngrok import ngrok, conf\nexcept ImportError:\n    print(\"Installing pyngrok...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\"])\n    from pyngrok import ngrok, conf\n\nNGROK_AUTH_TOKEN = \"\"  # @param {type:\"string\"}\n\nif not NGROK_AUTH_TOKEN:\n    print(\"‚ö†Ô∏è Please enter your ngrok auth token above!\")\n    print(\"   Get it from: https://dashboard.ngrok.com/get-started/your-authtoken\")\nelse:\n    conf.get_default().auth_token = NGROK_AUTH_TOKEN\n    print(\"‚úÖ ngrok authenticated successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 2: Deploy STT Service (Speech-to-Text)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# @title 2.1 Create STT Service with Faster-Whisper\n\n# Ensure dependencies are installed\nimport subprocess\nimport sys\n\ndef install_if_missing(package, import_name=None):\n    import_name = import_name or package\n    try:\n        __import__(import_name)\n    except ImportError:\n        print(f\"Installing {package}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n\ninstall_if_missing(\"faster-whisper\", \"faster_whisper\")\ninstall_if_missing(\"fastapi\")\ninstall_if_missing(\"uvicorn\")\ninstall_if_missing(\"python-multipart\")\ninstall_if_missing(\"nest_asyncio\")\n\nimport io\nimport numpy as np\nfrom fastapi import FastAPI, File, UploadFile, Form\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom typing import List, Dict, Any, Optional\nimport uvicorn\nimport threading\nimport torch\n\n# Initialize Faster-Whisper model\nprint(\"Loading Faster-Whisper model (large-v3)... This may take a few minutes.\")\nfrom faster_whisper import WhisperModel\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ncompute_type = \"float16\" if device == \"cuda\" else \"int8\"\n\nstt_model = WhisperModel(\"large-v3\", device=device, compute_type=compute_type)\nprint(f\"‚úÖ STT Model loaded on {device.upper()}\")\n\n# Create FastAPI app for STT\nstt_app = FastAPI(title=\"STT Service\")\n\nclass TimestampSegment(BaseModel):\n    start: float\n    end: float\n    word: Optional[str] = None\n    confidence: Optional[float] = None\n\nclass SttResponse(BaseModel):\n    text: str\n    language: str\n    confidence: float\n    timestamps: List[Dict[str, Any]]\n    meta: Dict[str, Any]\n    modelUsed: str\n    status: str = \"success\"\n\n@stt_app.get(\"/ml/stt/health\")\nasync def stt_health():\n    return {\n        \"status\": \"ok\",\n        \"detail\": \"stt-service healthy\",\n        \"models\": [{\"name\": \"whisper_large-v3\", \"status\": \"ready\", \"type\": \"stt\"}]\n    }\n\n@stt_app.post(\"/ml/stt/transcribe\", response_model=SttResponse)\nasync def transcribe(\n    file: UploadFile = File(...),\n    language_hint: Optional[str] = Form(default=None)\n):\n    try:\n        # Read audio file\n        audio_bytes = await file.read()\n\n        import tempfile\n        import os\n\n        # Save to temp file for faster-whisper\n        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as tmp:\n            tmp.write(audio_bytes)\n            tmp_path = tmp.name\n\n        # Transcribe with Faster-Whisper\n        segments, info = stt_model.transcribe(\n            tmp_path,\n            language=language_hint if language_hint else None,\n            word_timestamps=True,\n            vad_filter=True,\n            beam_size=5\n        )\n\n        # Process results\n        full_text_parts = []\n        all_timestamps = []\n        total_confidence = 0.0\n        segment_count = 0\n\n        for segment in segments:\n            full_text_parts.append(segment.text.strip())\n            segment_count += 1\n\n            # Calculate confidence from avg_logprob\n            segment_confidence = min(1.0, max(0.0, 1.0 + (segment.avg_logprob / 5.0)))\n            total_confidence += segment_confidence\n\n            # Extract word timestamps\n            if segment.words:\n                for word in segment.words:\n                    all_timestamps.append({\n                        \"start\": round(word.start, 3),\n                        \"end\": round(word.end, 3),\n                        \"word\": word.word.strip(),\n                        \"confidence\": round(segment_confidence, 3)\n                    })\n\n        # Clean up temp file\n        os.unlink(tmp_path)\n\n        full_text = \" \".join(full_text_parts).strip()\n        avg_confidence = total_confidence / max(segment_count, 1)\n\n        return SttResponse(\n            text=full_text,\n            language=info.language or language_hint or \"en\",\n            confidence=round(avg_confidence, 3),\n            timestamps=all_timestamps,\n            meta={\n                \"duration_seconds\": round(info.duration, 2),\n                \"file_name\": file.filename,\n                \"file_size\": len(audio_bytes)\n            },\n            modelUsed=\"whisper_large-v3:faster-whisper\"\n        )\n\n    except Exception as e:\n        return JSONResponse(\n            status_code=500,\n            content={\"error\": str(e), \"status\": \"failed\"}\n        )\n\nprint(\"‚úÖ STT Service created\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# @title 2.2 Start STT Service & Create ngrok Tunnel\nimport nest_asyncio\nnest_asyncio.apply()\n\n# Start STT server in background thread\nSTT_PORT = 8002\n\ndef run_stt_server():\n    uvicorn.run(stt_app, host=\"0.0.0.0\", port=STT_PORT, log_level=\"warning\")\n\nstt_thread = threading.Thread(target=run_stt_server, daemon=True)\nstt_thread.start()\n\nimport time\ntime.sleep(3)  # Wait for server to start\n\n# Create ngrok tunnel for STT\nfrom pyngrok import ngrok\n\nstt_tunnel = ngrok.connect(STT_PORT, \"http\")\nSTT_URL = stt_tunnel.public_url\n\nprint(\"=\"*60)\nprint(\"‚úÖ STT SERVICE DEPLOYED!\")\nprint(\"=\"*60)\nprint(f\"üåê Public URL: {STT_URL}\")\nprint(f\"üè• Health Check: {STT_URL}/ml/stt/health\")\nprint(f\"üé§ Transcribe: {STT_URL}/ml/stt/transcribe\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 3: Deploy TTS Service (Text-to-Speech)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# @title 3.1 Create TTS Service with Coqui XTTS\n\n# Ensure TTS is installed\nimport subprocess\nimport sys\n\ntry:\n    from TTS.api import TTS\nexcept ImportError:\n    print(\"Installing TTS (Coqui)... This may take a minute.\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"TTS\"])\n    from TTS.api import TTS\n\nimport os\nimport uuid\nimport base64\nimport torch\n\n# Initialize TTS model\nprint(\"Loading Coqui XTTS v2 model... This may take a few minutes.\")\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntts_model = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\nprint(f\"‚úÖ TTS Model loaded on {device.upper()}\")\n\n# Create output directory\nos.makedirs(\"/content/tts_output\", exist_ok=True)\n\n# Create FastAPI app for TTS\nfrom fastapi import FastAPI\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, Optional\n\ntts_app = FastAPI(title=\"TTS Service\")\n\nclass TtsRequest(BaseModel):\n    text: str\n    language: str = \"en\"\n    speed: float = 1.0\n    speaker_wav: Optional[str] = None\n\nclass TtsResponse(BaseModel):\n    audio_path: str\n    audio_base64: Optional[str] = None\n    duration: float\n    status: str\n    meta: Dict[str, Any]\n\n@tts_app.get(\"/ml/tts/health\")\nasync def tts_health():\n    return {\n        \"status\": \"ok\",\n        \"detail\": \"tts-service healthy\",\n        \"models\": [{\"name\": \"xtts_v2\", \"status\": \"ready\", \"type\": \"tts\"}]\n    }\n\n@tts_app.post(\"/ml/tts/predict\", response_model=TtsResponse)\nasync def synthesize(request: TtsRequest):\n    try:\n        # Generate unique filename\n        output_filename = f\"/content/tts_output/{uuid.uuid4().hex}.wav\"\n\n        # Synthesize speech\n        tts_model.tts_to_file(\n            text=request.text,\n            language=request.language,\n            file_path=output_filename,\n            speed=request.speed\n        )\n\n        # Get audio duration\n        import wave\n        with wave.open(output_filename, 'r') as wav_file:\n            frames = wav_file.getnframes()\n            rate = wav_file.getframerate()\n            duration = frames / float(rate)\n\n        # Read audio as base64 for response\n        with open(output_filename, 'rb') as f:\n            audio_base64 = base64.b64encode(f.read()).decode('utf-8')\n\n        return TtsResponse(\n            audio_path=output_filename,\n            audio_base64=audio_base64,\n            duration=round(duration, 2),\n            status=\"success\",\n            meta={\n                \"language\": request.language,\n                \"speed\": request.speed,\n                \"model\": \"xtts_v2\",\n                \"text_length\": len(request.text)\n            }\n        )\n\n    except Exception as e:\n        return JSONResponse(\n            status_code=500,\n            content={\"error\": str(e), \"status\": \"failed\"}\n        )\n\nprint(\"‚úÖ TTS Service created\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# @title 3.2 Start TTS Service & Create ngrok Tunnel\n# Start TTS server in background thread\nTTS_PORT = 8001\n\ndef run_tts_server():\n    uvicorn.run(tts_app, host=\"0.0.0.0\", port=TTS_PORT, log_level=\"warning\")\n\ntts_thread = threading.Thread(target=run_tts_server, daemon=True)\ntts_thread.start()\n\ntime.sleep(3)  # Wait for server to start\n\n# Create ngrok tunnel for TTS\ntts_tunnel = ngrok.connect(TTS_PORT, \"http\")\nTTS_URL = tts_tunnel.public_url\n\nprint(\"=\"*60)\nprint(\"‚úÖ TTS SERVICE DEPLOYED!\")\nprint(\"=\"*60)\nprint(f\"üåê Public URL: {TTS_URL}\")\nprint(f\"üè• Health Check: {TTS_URL}/ml/tts/health\")\nprint(f\"üîä Synthesize: {TTS_URL}/ml/tts/predict\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# @title 3.3 Deployment Summary - SAVE THESE URLs!\nprint(\"=\"*70)\nprint(\"üéâ DEPLOYMENT COMPLETE! Both services are running.\")\nprint(\"=\"*70)\nprint()\nprint(\"üìç STT Service (Speech-to-Text):\")\nprint(f\"   URL: {STT_URL}\")\nprint(f\"   Health: {STT_URL}/ml/stt/health\")\nprint(f\"   Transcribe: {STT_URL}/ml/stt/transcribe\")\nprint()\nprint(\"üìç TTS Service (Text-to-Speech):\")\nprint(f\"   URL: {TTS_URL}\")\nprint(f\"   Health: {TTS_URL}/ml/tts/health\")\nprint(f\"   Synthesize: {TTS_URL}/ml/tts/predict\")\nprint()\nprint(\"=\"*70)\nprint(\"‚ö†Ô∏è  IMPORTANT: These URLs will change if you restart the notebook!\")\nprint(\"=\"*70)\n\n# Set headers for all subsequent requests\nHEADERS = {\"ngrok-skip-browser-warning\": \"true\"}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 4: Health Checks",
   "metadata": {
    "id": "health-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Check STT Service Health\n",
    "def check_stt_health():\n",
    "    try:\n",
    "        response = requests.get(f\"{STT_URL}/ml/stt/health\", headers=HEADERS, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(\"‚úÖ STT Service is HEALTHY\")\n",
    "            print(f\"   Status: {data.get('status')}\")\n",
    "            print(f\"   Models: {len(data.get('models', []))} loaded\")\n",
    "            for model in data.get('models', []):\n",
    "                print(f\"     - {model.get('name')}: {model.get('status')}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå STT Service returned HTTP {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå STT Service is UNREACHABLE: {e}\")\n",
    "        return False\n",
    "\n",
    "check_stt_health()"
   ],
   "metadata": {
    "id": "stt-health"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Check TTS Service Health\n",
    "def check_tts_health():\n",
    "    try:\n",
    "        response = requests.get(f\"{TTS_URL}/ml/tts/health\", headers=HEADERS, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(\"‚úÖ TTS Service is HEALTHY\")\n",
    "            print(f\"   Status: {data.get('status')}\")\n",
    "            print(f\"   Models: {len(data.get('models', []))} loaded\")\n",
    "            for model in data.get('models', []):\n",
    "                print(f\"     - {model.get('name')}: {model.get('status')}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå TTS Service returned HTTP {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå TTS Service is UNREACHABLE: {e}\")\n",
    "        return False\n",
    "\n",
    "check_tts_health()"
   ],
   "metadata": {
    "id": "tts-health"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 5: STT Testing (Speech-to-Text)",
   "metadata": {
    "id": "stt-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Upload Audio File for Transcription\n",
    "print(\"Upload an audio file (WAV, MP3, FLAC, etc.)\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    audio_filename = list(uploaded.keys())[0]\n",
    "    print(f\"\\n‚úÖ Uploaded: {audio_filename}\")\n",
    "    print(f\"   Size: {len(uploaded[audio_filename])} bytes\")\n",
    "else:\n",
    "    print(\"No file uploaded\")\n",
    "    audio_filename = None"
   ],
   "metadata": {
    "id": "upload-audio"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Transcribe Uploaded Audio\n",
    "# @markdown Select the language hint (or leave empty for auto-detect)\n",
    "language_hint = \"en\"  # @param [\"en\", \"hi\", \"ta\", \"te\", \"es\", \"fr\", \"de\", \"ja\", \"zh\", \"\"]\n",
    "\n",
    "if audio_filename:\n",
    "    print(f\"Transcribing: {audio_filename}\")\n",
    "    print(f\"Language hint: {language_hint or 'auto-detect'}\")\n",
    "    print(\"\\nProcessing... (this may take 30-60 seconds on first request)\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with open(audio_filename, 'rb') as f:\n",
    "        files_data = {\"file\": (audio_filename, f)}\n",
    "        data = {\"language_hint\": language_hint} if language_hint else {}\n",
    "\n",
    "        response = requests.post(\n",
    "            f\"{STT_URL}/ml/stt/transcribe\",\n",
    "            files=files_data,\n",
    "            data=data,\n",
    "            headers=HEADERS,\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"\\n‚úÖ Transcription Complete ({elapsed:.2f}s)\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"üìù Text: {result['text']}\")\n",
    "        print(f\"üåç Language: {result['language']}\")\n",
    "        print(f\"üìä Confidence: {result['confidence']:.2%}\")\n",
    "        print(f\"‚è±Ô∏è Duration: {result['meta'].get('duration_seconds', 'N/A')}s\")\n",
    "        print(f\"ü§ñ Model: {result.get('modelUsed', 'N/A')}\")\n",
    "\n",
    "        # Show word timestamps\n",
    "        if result.get('timestamps'):\n",
    "            print(f\"\\nüìç Word Timestamps ({len(result['timestamps'])} words):\")\n",
    "            for ts in result['timestamps'][:10]:  # Show first 10\n",
    "                print(f\"   [{ts['start']:.2f}s - {ts['end']:.2f}s] {ts['word']}\")\n",
    "            if len(result['timestamps']) > 10:\n",
    "                print(f\"   ... and {len(result['timestamps'])-10} more words\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Transcription Failed: HTTP {response.status_code}\")\n",
    "        print(response.text)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please upload an audio file first\")"
   ],
   "metadata": {
    "id": "transcribe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 6: TTS Testing (Text-to-Speech)",
   "metadata": {
    "id": "tts-test-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Synthesize Speech from Text\n",
    "# @markdown Enter the text you want to convert to speech\n",
    "\n",
    "text_to_synthesize = \"Hello! This is a test of the text to speech system.\"  # @param {type:\"string\"}\n",
    "tts_language = \"en\"  # @param [\"en\", \"hi\", \"ta\", \"te\", \"es\", \"fr\", \"de\", \"ja\", \"zh-cn\"]\n",
    "speech_speed = 1.0  # @param {type:\"slider\", min:0.5, max:2.0, step:0.1}\n",
    "\n",
    "print(f\"Text: {text_to_synthesize}\")\n",
    "print(f\"Language: {tts_language}\")\n",
    "print(f\"Speed: {speech_speed}x\")\n",
    "print(\"\\nGenerating speech... (this may take 30-60 seconds on first request)\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{TTS_URL}/ml/tts/predict\",\n",
    "    json={\n",
    "        \"text\": text_to_synthesize,\n",
    "        \"language\": tts_language,\n",
    "        \"speed\": speech_speed\n",
    "    },\n",
    "    headers={\"Content-Type\": \"application/json\", **HEADERS},\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"\\n‚úÖ Speech Generated ({elapsed:.2f}s)\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"‚è±Ô∏è Duration: {result['duration']:.2f}s\")\n",
    "    print(f\"üìä Status: {result['status']}\")\n",
    "    print(f\"üéØ MOS Score: {result['meta'].get('mos_score', 'N/A')}\")\n",
    "    print(f\"üìÅ Server Path: {result['audio_path']}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Speech Generation Failed: HTTP {response.status_code}\")\n",
    "    print(response.text)"
   ],
   "metadata": {
    "id": "synthesize"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 7: Multi-Language Testing",
   "metadata": {
    "id": "multilang-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Test TTS with Multiple Languages\n",
    "test_texts = {\n",
    "    \"en\": \"Hello, how are you today?\",\n",
    "    \"hi\": \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?\",\n",
    "    \"es\": \"Hola, c√≥mo est√°s hoy?\",\n",
    "    \"fr\": \"Bonjour, comment allez-vous?\",\n",
    "    \"de\": \"Hallo, wie geht es Ihnen?\",\n",
    "    \"ja\": \"„Åì„Çì„Å´„Å°„ÅØ„ÄÅ„ÅäÂÖÉÊ∞ó„Åß„Åô„ÅãÔºü\",\n",
    "    \"zh-cn\": \"‰Ω†Â•ΩÔºå‰Ω†‰ªäÂ§©ÊÄé‰πàÊ†∑Ôºü\"\n",
    "}\n",
    "\n",
    "print(\"Testing TTS in multiple languages...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for lang, text in test_texts.items():\n",
    "    try:\n",
    "        start = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{TTS_URL}/ml/tts/predict\",\n",
    "            json={\"text\": text, \"language\": lang},\n",
    "            headers={\"Content-Type\": \"application/json\", **HEADERS},\n",
    "            timeout=60\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ {lang.upper()}: {text[:30]}... ({data['duration']:.1f}s audio, {elapsed:.1f}s processing)\")\n",
    "            results[lang] = {\"success\": True, \"duration\": data['duration']}\n",
    "        else:\n",
    "            print(f\"‚ùå {lang.upper()}: Failed (HTTP {response.status_code})\")\n",
    "            results[lang] = {\"success\": False}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {lang.upper()}: Error ({e})\")\n",
    "        results[lang] = {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "print(\"=\"*60)\n",
    "success_count = sum(1 for r in results.values() if r['success'])\n",
    "print(f\"\\nResults: {success_count}/{len(test_texts)} languages successful\")"
   ],
   "metadata": {
    "id": "multilang-test"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 8: Performance Measurement",
   "metadata": {
    "id": "performance-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Measure TTS Latency\n",
    "num_runs = 3  # @param {type:\"slider\", min:1, max:10, step:1}\n",
    "\n",
    "print(f\"Running {num_runs} TTS requests to measure latency...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "times = []\n",
    "test_text = \"Quick latency test.\"\n",
    "\n",
    "for i in range(num_runs):\n",
    "    start = time.time()\n",
    "    response = requests.post(\n",
    "        f\"{TTS_URL}/ml/tts/predict\",\n",
    "        json={\"text\": test_text, \"language\": \"en\"},\n",
    "        headers={\"Content-Type\": \"application/json\", **HEADERS},\n",
    "        timeout=60\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        times.append(elapsed)\n",
    "        print(f\"   Run {i+1}: {elapsed:.2f}s\")\n",
    "    else:\n",
    "        print(f\"   Run {i+1}: Failed\")\n",
    "\n",
    "if times:\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nüìä Latency Statistics:\")\n",
    "    print(f\"   Min:  {min(times):.2f}s\")\n",
    "    print(f\"   Max:  {max(times):.2f}s\")\n",
    "    print(f\"   Avg:  {sum(times)/len(times):.2f}s\")"
   ],
   "metadata": {
    "id": "latency-test"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 9: Integration Test (Round Trip)",
   "metadata": {
    "id": "integration-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title STT ‚Üí TTS Round Trip Test\n",
    "# @markdown This test transcribes audio and then synthesizes it back to speech\n",
    "\n",
    "if audio_filename and os.path.exists(audio_filename):\n",
    "    print(\"Starting round-trip test...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Step 1: Transcribe\n",
    "    print(\"\\n[Step 1] Transcribing audio...\")\n",
    "    start = time.time()\n",
    "\n",
    "    with open(audio_filename, 'rb') as f:\n",
    "        stt_response = requests.post(\n",
    "            f\"{STT_URL}/ml/stt/transcribe\",\n",
    "            files={\"file\": f},\n",
    "            headers=HEADERS,\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "    stt_time = time.time() - start\n",
    "\n",
    "    if stt_response.status_code == 200:\n",
    "        stt_result = stt_response.json()\n",
    "        print(f\"   ‚úÖ Transcribed ({stt_time:.2f}s)\")\n",
    "        print(f\"   Text: {stt_result['text'][:100]}...\")\n",
    "        print(f\"   Language: {stt_result['language']}\")\n",
    "\n",
    "        # Step 2: Synthesize\n",
    "        print(\"\\n[Step 2] Synthesizing speech...\")\n",
    "        start = time.time()\n",
    "\n",
    "        tts_response = requests.post(\n",
    "            f\"{TTS_URL}/ml/tts/predict\",\n",
    "            json={\n",
    "                \"text\": stt_result['text'],\n",
    "                \"language\": stt_result['language']\n",
    "            },\n",
    "            headers={\"Content-Type\": \"application/json\", **HEADERS},\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "        tts_time = time.time() - start\n",
    "\n",
    "        if tts_response.status_code == 200:\n",
    "            tts_result = tts_response.json()\n",
    "            print(f\"   ‚úÖ Synthesized ({tts_time:.2f}s)\")\n",
    "            print(f\"   Duration: {tts_result['duration']:.2f}s\")\n",
    "\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"üìä Round-Trip Summary:\")\n",
    "            print(f\"   STT Time: {stt_time:.2f}s\")\n",
    "            print(f\"   TTS Time: {tts_time:.2f}s\")\n",
    "            print(f\"   Total Time: {stt_time + tts_time:.2f}s\")\n",
    "            print(\"   ‚úÖ Round-trip test PASSED!\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå TTS failed: {tts_response.status_code}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå STT failed: {stt_response.status_code}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please upload an audio file first (in the STT section above)\")"
   ],
   "metadata": {
    "id": "round-trip"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 10: Custom Testing",
   "metadata": {
    "id": "custom-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Custom TTS Request\n",
    "# @markdown Use this cell to test with any text\n",
    "\n",
    "custom_text = \"Enter your custom text here\"  # @param {type:\"string\"}\n",
    "custom_lang = \"en\"  # @param {type:\"string\"}\n",
    "custom_speed = 1.0  # @param {type:\"number\"}\n",
    "\n",
    "print(f\"Sending custom TTS request...\")\n",
    "print(f\"  Text: {custom_text}\")\n",
    "print(f\"  Language: {custom_lang}\")\n",
    "print(f\"  Speed: {custom_speed}\")\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{TTS_URL}/ml/tts/predict\",\n",
    "    json={\n",
    "        \"text\": custom_text,\n",
    "        \"language\": custom_lang,\n",
    "        \"speed\": custom_speed\n",
    "    },\n",
    "    headers={\"Content-Type\": \"application/json\", **HEADERS},\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "print(f\"\\nResponse ({response.status_code}):\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ],
   "metadata": {
    "id": "custom-tts"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 11: Test Summary",
   "metadata": {
    "id": "summary-header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Generate Test Summary\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüîó Service URLs:\")\n",
    "print(f\"   STT: {STT_URL}\")\n",
    "print(f\"   TTS: {TTS_URL}\")\n",
    "\n",
    "print(f\"\\nüè• Service Health:\")\n",
    "stt_ok = check_stt_health()\n",
    "tts_ok = check_tts_health()\n",
    "\n",
    "print(f\"\\nüìã Overall Status:\")\n",
    "if stt_ok and tts_ok:\n",
    "    print(\"   ‚úÖ All services are operational!\")\n",
    "elif stt_ok:\n",
    "    print(\"   ‚ö†Ô∏è Only STT service is operational\")\n",
    "elif tts_ok:\n",
    "    print(\"   ‚ö†Ô∏è Only TTS service is operational\")\n",
    "else:\n",
    "    print(\"   ‚ùå Both services are down\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ],
   "metadata": {
    "id": "summary"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}